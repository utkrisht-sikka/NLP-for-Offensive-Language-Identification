{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdsCuszxMK5k"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq12OnpbM-Ex",
        "outputId": "4ac13a7e-4664-4f0e-df8f-6571f4a25ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n",
            "0.7154926624737946\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Source\n",
        "https://www.kaggle.com/code/feyzazkefe/lstm-twitter-offensive\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, f1_score\n",
        "from sklearn import metrics\n",
        "from keras.layers import LSTM,  Dense, Dropout, Embedding, Bidirectional\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf\n",
        "from copy import deepcopy\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(\"ignore\")\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "\n",
        "# learn the weights w1 and w2 s.t. w1+w2 = 1 and w1 is weight given to probability of lstm\n",
        "# p1w1 + p2w2 over validation set. Obtain w1. Try on test set.\n",
        "datapath = \"/content/drive/MyDrive/NLP/H1_Offensive_Language_Identification_train.csv\"\n",
        "trainset = pd.read_csv(datapath);\n",
        " \n",
        "\n",
        "trainset.update(trainset[['tweet']].applymap('\\'{}\\''.format))\n",
        " \n",
        "trainset, valset = train_test_split(\n",
        "  trainset,\n",
        "  test_size=0.1,\n",
        "  random_state=RANDOM_SEED\n",
        ")\n",
        "encoder = LabelEncoder()\n",
        " \n",
        "valset[\"class_a_code\"] = encoder.fit_transform(valset[\"label\"])\n",
        "\n",
        "y_val = valset[\"class_a_code\"]\n",
        "y_val2 = list(y_val)\n",
        "\n",
        "#load probabilities of lstm on validation and test set\n",
        "import pickle\n",
        "y_predlstm_val = pickle.load(open(\"lstm_predict_val.pkl\", 'rb'))\n",
        " \n",
        "\n",
        "\n",
        "#load probabilities of BERT on validation and test set\n",
        "import pickle\n",
        "y_predbert_val = pickle.load(open(\"BERT_predict_val.pkl\", 'rb'))\n",
        " \n",
        "\n",
        "def givew1(y_predlstm, y_predbert, y_val2):\n",
        "  bestw = None\n",
        "  bestf1 = -1\n",
        "  for ww in range(0, 101, 1):\n",
        "    w=ww/100\n",
        "    y_final = []\n",
        "    for i in range(len(y_predlstm)):\n",
        "      y_final.append((w*y_predlstm[i]) + ((1-w)*y_predbert[i]))\n",
        "\n",
        "    for i in range(len(y_final)):\n",
        "        if(y_final[i] > 0.5):\n",
        "            y_final[i] = 1\n",
        "        else:\n",
        "            y_final[i] =0\n",
        "    newf1 = f1_score(y_val2, y_final, average='macro')\n",
        "    print(newf1)\n",
        "    if(newf1 > bestf1):\n",
        "      bestf1 = newf1\n",
        "      bestw = w\n",
        "  return bestw\n",
        "\n",
        "bestweight = givew1(y_predlstm_val, y_predbert_val, y_val2)\n",
        "\n",
        " \n",
        "#OFF = 1, NOT = 0"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
